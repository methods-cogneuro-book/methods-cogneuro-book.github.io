---
jupytext:
  cell_metadata_filter: -all
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.10.3
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---
(reproductibilite-controverses-chapitre)=
# Reproductibilit√© et controverses
<table>
  <tr>
    <td align="center">
      <a href="https://github.com/elisabethloranger">
        <img src="https://avatars.githubusercontent.com/u/90270981?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>√âlisabeth Loranger</b></sub>
      </a>
      <br />
        <a title="Contenu">ü§î</a>
    </td>
    <td align="center">
      <a href="https://github.com/pbellec">
        <img src="https://avatars.githubusercontent.com/u/1670887?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>Pierre bellec</b></sub>
      </a>
      <br />
        <a title="Contenu">ü§î</a>
    </td>
    <td align="center">
      <a href="https://github.com/eddyfortier">
        <img src="https://avatars.githubusercontent.com/u/72314243?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>Eddy Fortier</b></sub>
      </a>
      <br />
        <a title="R√©vision du texte">üëÄ</a>
    </td>
    <td align="center">
      <a href="https://github.com/me-pic">
        <img src="https://avatars.githubusercontent.com/u/77584086?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>Marie-Eve Picard</b></sub>
      </a>
      <br />
        <a title="R√©vision du texte">üëÄ</a>
    </td>
  </tr>
</table>


Durant ce cours, nous avons effectu√© un survol de diverses techniques de neuroimagerie qui ouvrent une fen√™tre fascinante sur la structure et la fonction du cerveau. Par contre, ces techniques sont r√©guli√®rement pr√©sent√©es dans des articles scientifiques qui semblent peu cr√©dibles. Dans cet ultime cours, nous allons discuter des controverses entourant la neuroimagerie, et de fa√ßon plus large, de la crise de reproductibilit√© en sciences.

Les objectifs de ce cours sont les suivants :
- Comprendre la crise de reproductibilit√© en sciences.
- Comprendre certaines pratiques scientifiques douteuses qui participent au manque de reproductibilit√© en neurosciences cognitives.
- Conna√Ætre certains outils qui peuvent am√©liorer la reproductibilit√© en neurosciences cognitives.

## La crise de reproductibilit√©

### Une crise? Quelle crise?
```{figure} ./reproductibilite/significant.png
---
width: 600px
name: significant-fig
---
Cette figure illustre un exemple de processus pouvant amener √† un r√©sultat scientifique controvers√© (ainsi qu'un exemple de probl√®me de comparaisons multiples). Cette figure est tir√©e de [xkcd webcomic](https://xkcd.com/882/), sous licence [CC-BY-NC 2.5](https://creativecommons.org/licenses/by-nc/2.5/).
```

En 2016, un sondage effectu√© aupr√®s de 1576 chercheurs a √©t√© men√© dans le but de voir si, dans la
perception des professionnels dans la recherche, il y avait une crise de
reproductibilit√©, et si oui, laquelle ([Baker, 2016](https://doi.org/10.1038/533452a)).
En tout, 90% des chercheurs ont affirm√© dans ce sondage qu'ils pensaient qu‚Äôil y avait effectivement une crise de reproductibilit√© (52% pour une crise significative et 38% pour une crise mod√©r√©e).

La reproductibilit√©, c‚Äôest quoi? Si nous avions acc√®s
aux donn√©es derri√®re ce papier, serait-on capable de refaire les
analyses et d'arriver aux m√™mes conclusions? Un autre concept proche est la r√©plicabilit√©: en recrutant de nouveaux sujets (nouvel √©chantillon) et en faisant exactement ce que les autres chercheurs avaient fait au niveau des outils utilis√©s et des analyses effectu√©es, est-ce que nous trouverions les m√™mes r√©sultats?
Dans le sondage, 70% des personnes sond√©es rapportaient avoir √©chou√© √† reproduire les r√©sultats d'une autre √©quipe de recherche et plus de 50% d'entre eux rapportaient m√™me avoir √©chou√© √† reproduire leurs propres r√©sultats.

Les personnes sond√©es ont aussi √©valu√© les causes probables de cette crise de
reproductibilit√©. Parmi les raisons les plus fr√©quemment mentionn√©es,
on retrouve la _pression de publier_, la _publication s√©lective_ (les gens ne publient
seulement que ce qui fonctionne bien) ainsi que la _puissance statistique limit√©e_.
Ce chapitre cherchera √† expliquer certaines de ces notions plus en d√©tail en commen√ßant par formaliser le processus de g√©n√©ration de connaissances scientifiques.

### La m√©thode scientifique
```{figure} ./reproductibilite/researchcycle_original.png
---
width: 800px
name: researchcycle-original-fig
---
Cette figure illustre le cycle des d√©couvertes scientifiques selon l'approche de la m√©thode scientifique d√©crite par [Karl Popper](https://fr.wikipedia.org/wiki/Karl_Popper#Philosophie_des_sciences). Figure adapt√©e d'un travail original par [scriberia](https://info.scriberia.com/contact-us) dans le cadre du livre [The Turing way](https://the-turing-way.netlify.app) sous licence [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/), DOI: [10.5281/zenodo.3332807](https://doi.org/10.5281/zenodo.3332807). La figure adapt√©e par P. Bellec est elle-m√™me disponible sous licence [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
La {numref}`researchcycle-original-fig` pr√©sente une version simplifi√©e de la m√©thode scientifique impliqu√©e dans la d√©couverte de connaissances, inspir√©e par la th√©orie de [Karl Popper](https://fr.wikipedia.org/wiki/Karl_Popper#Philosophie_des_sciences), telle qu'elle est g√©n√©ralement impl√©ment√©e dans la communaut√© de recherche.
 * On commence avec une consultation des publications ant√©rieures: celles-ci repr√©sentent les connaissances qui ont √©t√© accumul√©es par d‚Äôautres chercheurs avant nous.
 * En lisant cette litt√©rature, les chercheuses/chercheurs peuvent prendre connaissance de ce qui a d√©j√† √©t√© d√©couvert et formuler des hypoth√®ses en lien avec ce que l'on sait d√©j√† sur des choses qu‚Äôon ne conna√Æt pas encore.
 * Les chercheuses/chercheurs vont alors construire un devis de recherche: nombre de participants, groupes, tests statistiques, etc. Elles/ils vont aussi faire des pr√©dictions concernant les r√©sultats qu‚Äôelles/ils pensent obtenir.
 * Une fois le devis de recherche √©labor√©, il est maintenant temps de recueillir les donn√©es.
 * Ensuite, on analyse les donn√©es en suivant le protocole qui avait √©t√© √©tabli dans le devis de recherche.
 * Il faut alors interpr√©ter les r√©sultats et notamment les comparer √† nos pr√©dictions pour valider ou invalider nos hypoth√®ses.
 * Les r√©sultats de la recherche sont alors publi√©s pour permettre au reste de la communaut√© de recherche de continuer √† formuler de nouvelles hypoth√®ses.

Comme on utilise des statistiques rigoureuses dans cette approche, on ne g√©n√®re qu'une quantit√© limit√©e de faux positifs, et donc, on fait des d√©couvertes scientifiques sans faire trop d'erreurs. En pratique, cette approche peut √™tre adapt√©e de nombreuses mani√®res en y incluant _des pratiques de recherche douteuses_ qui vont compromettre l'int√©grit√© et la rigueur des conclusions de l'√©tude.

### La m√©thode scientifique: hacked
```{figure} ./reproductibilite/researchcycle_hacked.png
---
width: 800px
name: researchcycle-hacked-fig
---
Cette figure illustre les pratiques douteuses qui peuvent affecter n√©gativement l'int√©grit√© du cycle des d√©couvertes scientifiques. Figure adapt√©e d'un travail original par [scriberia](https://info.scriberia.com/contact-us) dans le cadre du livre [The Turing way](https://the-turing-way.netlify.app) sous licence [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/), DOI: [10.5281/zenodo.3332807](https://doi.org/10.5281/zenodo.3332807). La figure int√®gre aussi une image [shutterstock](https://www.shutterstock.com/image-vector/computer-hacker-laptop-icon-787273936), utilis√©e sous licence shutterstock standard.
```
#### Biais de publication
La publication s√©lective est un des probl√®mes les plus importants identifi√©s dans le sondage vu plus t√¥t. Cela signifie que les r√©sultats d'une √©tude ne sont publi√©s que lorsqu‚Äôils sont positifs, c'est-√†-dire uniquement s'ils confirment les hypoth√®ses de l'√©quipe de recherche. Si ce type de pratique est syst√©matique dans une communaut√© de recherche, il se peut que plusieurs groupes rapportent un r√©sultat, qui semblera alors robuste, alors qu'en fait, un nombre plus important de groupes de recherche n'ont pas pu r√©pliquer cet effet et ne l'ont donc jamais publi√©. Cela vient d√©former compl√®tement la collection de connaissances accumul√©e par la communaut√© scientifique, collection qui sera elle-m√™me √† l'origine des hypoth√®ses des √©tudes futures.

#### p-hacking
Si nous voyons que nos r√©sultats ne correspondent pas √† nos attentes, il est possible que nous nous demandions si nous avons commis une erreur ou si nous avons bien choisi la technique d'analyse optimale. Nous risquons alors de revisiter la mani√®re
√† laquelle nous analysons les donn√©es jusqu'√† ce que les r√©sultats deviennent significatifs. Ce type d'approche a √©t√© baptis√© _p-hacking_. Le p-hacking peut prendre de nombreuses formes: exclusion arbitraire de "valeurs aberrantes", s√©lection d'un sous-groupe qui montre l'effet attendu, changement des param√®tres de pr√©traitement, etc.

#### HARKing
La derni√®re pratique douteuse est baptis√©e le ¬´ HARKing ¬ª. Le terme HARK est un acronyme originaire de l'anglais pour les termes ¬´ Hypothesis after results are known ¬ª, ou bien "d√©finition des hypoth√®ses apr√®s que les r√©sultats soient connus". On va effectuer de nombreux tests √† partir des donn√©es recueillies et on va formuler a posteriori des hypoth√®ses correspondant aux r√©sultats significatifs dans l'√©chantillon. Ce processus n'est pas n√©cessairement malicieux, mais il peut √©merger d'une volont√© d'interpr√©ter les donn√©es √† tout prix. Cette d√©marche n'est pas n√©cessairement probl√©matique, du moment que les hypoth√®ses sont (correctement) pr√©sent√©es comme √©tant de nature exploratoire, guid√©es par les donn√©es, plut√¥t que comme des hypoth√®ses formul√©es a priori de fa√ßon rigoureuse.

## Reproductibilit√© et neuroimagerie
Nous allons maintenant voir comment la neuroimagerie repr√©sente un domaine particuli√®rement propice au p-hacking, ainsi que d'autres facteurs qui peuvent contribuer au manque de reproductibilit√©. Ces facteurs sont tous li√©s √† la complexit√© des cha√Ænes de traitement en neuroimagerie.
 * Tout d'abord, il est possible de faire varier de fa√ßon importante les conclusions d'une √©tude juste en modifiant les choix analytiques que l'on fait concernant la cha√Æne de traitement (ce que l'on appelle les **degr√©s de libert√© en recherche**).
 * Ensuite, il est possible de confondre les effets significatifs et les effets importants (on doit consid√©rer la **taille des effets**).
 * Enfin, √† cause de la complexit√© des m√©thodes utilis√©es, il est souvent difficile, voir impossible, de vraiment comprendre les m√©thodes utilis√©es dans un article seulement sur la base du texte de cet article (**m√©thodes incompl√®tes**).

### Degr√©s de libert√© en recherche
```{figure} ./reproductibilite/multi_analyses_fmri.png
---
width: 800px
name: multi-analyses-fmri-fig
---
Cette figure r√©sume les cartes d'activations IRMf g√©n√©r√©es par 64 √©quipes ind√©pendantes √† partir des m√™mes donn√©es et ayant pour objectif de tester la m√™me hypoth√®se. Les √©quipes ont √©t√© s√©par√©es en trois sous-groupes sur la base de la similarit√© spatiale de leurs cartes d'activation √† l'aide d'un algorithme automatique. Le premier groupe (cluster 1) est le plus gros, avec 50 √©quipes, alors que les deux autres sous-groupes incluent 7 √©quipes chacun. Notez les variations importantes entre les trois sous-groupes. Figure tir√©e de [Botvinik-Nezer et al., 2020](https://doi.org/10.1101/843193) sous licence [CC-BY-NC-ND 4.0](http://creativecommons.org/licenses/by-nc-nd/4.0/).
```
Pour chacune des techniques √©tudi√©es dans ces notes de cours, il est n√©cessaire d'impl√©menter une s√©rie d'√©tapes d'analyse et de choisir certains param√®tres pour chacune de ces √©tapes. Dans la mesure o√π l'on n'a pas de v√©rit√© de terrain √† laquelle se r√©f√©rer en neuroimagerie, il n'existe pas de consensus sur le choix optimal concernant ces param√®tres. De plus, ce choix est probablement d√©pendant de la population d'int√©r√™t et des questions de recherche dans une large mesure. Pour quantifier cette variabilit√©, une √©tude r√©cente a invit√© 70 √©quipes de recherche √† analyser le m√™me jeu de donn√©es par activation en IRMf [Botvinik-Nezer et al., 2020](https://doi.org/10.1101/843193) et √† tester les m√™mes hypoth√®ses. Un premier r√©sultat frappant est que chaque √©quipe a utilis√© une approche unique pour analyser les donn√©es, illustrant ainsi le manque criant de standardisation dans le domaine. Un autre r√©sultat frappant est que, pour une hypoth√®se donn√©e, certaines √©quipes ont produit des cartes tr√®s diff√©rentes (voir {numref}`multi-analyses-fmri-fig`). Bien que certains sous-groupes d'√©quipes aient identifi√© des cartes tr√®s similaires, certains choix ont amen√© √† des diff√©rences importantes. Par ailleurs, m√™me pour les √©quipes g√©n√©rant des cartes similaires, leur interpr√©tation de la carte pour r√©pondre √† l'hypoth√®se variait substantiellement!

```{admonition} Degr√©s de libert√© en recherche et p-hacking
:class: tip
:name: researcher-degrees-freedom-tip

Le nombre de param√®tres qu'un chercheur peut manipuler est appel√© _degr√© de libert√© en recherche_. Comme la neuroimagerie a un tr√®s grand nombre de degr√©s de libert√©, cela augmente le risque de p-hacking.
En effet, il est toujours possible de comparer plusieurs approches pour s√©lectionner la "meilleure", c'est-√†-dire celle qui am√®ne les r√©sultats les plus conformes aux hypoth√®ses de l'√©quipe de recherche.
```

```{admonition} Impact des logiciels d'analyse et de l'environnement virtuel
:class: caution attention
:name: software-warning
Au-del√† des param√®tres utilis√©s dans une analyse, des diff√©rences substantielles peuvent venir du choix du logiciel ou de la version du logiciel utilis√© ([Bowring et al., 2019](https://doi.org/10.1002/hbm.24603)). M√™me des changements mineurs peuvent avoir un impact sur les r√©sultats. Et cela n'est pas limit√© au logiciel de neuroimagerie en tant que tel. Un changement de syst√®me d'op√©ration peut lui aussi cr√©er des diff√©rences, par exemple, dans une analyse de morphom√©trie ([Gronenschild et al., 2012](https://doi.org/10.1371/journal.pone.0038234)).
```

### Tailles d'effet
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

def sample_data(d, n_samp=1000):
    samp1 = np.random.normal(loc=0, scale=1, size=n_samp)
    samp2 = np.random.normal(loc=d, scale=1, size=n_samp)
    return samp1, samp2

# On g√©n√®re une s√©rie de nombres al√©atoires
# avec diff√©rentes tailles d'effet
rs = np.random.RandomState(0)
list_d = [0, 0.3, 1, 2]
n_samp = 10000
df1 = pd.DataFrame()
df2 = pd.DataFrame()
for d in list_d:
    samp1, samp2 = sample_data(d, n_samp=n_samp)
    df1[f'{d}'] = samp1
    df2[f'{d}'] = samp2

# On stocke toutes les valeurs avec les param√®tres correspondants
# dans un pandas dataframe
df1 = df1.melt(var_name='d')
df1['group'] = 0
df2 = df2.melt(var_name='d')
df2['group'] = 1
df = pd.concat([df1, df2], ignore_index=True)

# On visualise les distributions
import seaborn as sns

sns.set_theme(style='darkgrid')
fig = sns.displot(
    df,     
    x='value',
    col='d',
    hue='group',
    kind='kde',
    fill=True,
)
fig.fig.set_dpi(300)

from myst_nb import glue
glue("effect-size-fig", fig.fig, display=False)
```
```{glue:figure} effect-size-fig
:figwidth: 800px
:name: effect-size-fig
Illustration de deux distributions de groupes suivant une loi normale pour diff√©rentes tailles d'effet mesur√©es avec le _d_ de Cohen. Figure g√©n√©r√©e avec du code python √† l'aide de la librairie [seaborn](https://seaborn.pydata.org/) (cliquer sur + pour voir le code). Cette figure produite par P. Bellec est distribu√©e sous licence [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
Une autre erreur commune en neuroimagerie est d‚Äôinterpr√©ter une diff√©rence significative comme √©tant une diff√©rence importante. Par exemple, imaginons que l'on trouve une diff√©rence significative concernant le volume de l'amygdale entre deux groupes: celui-ci serait r√©duit chez des personnes sur le spectre de l‚Äôautisme par rapport √† des individus neurotypiques. Cela signifierait que la diff√©rence de la moyenne des distributions est diff√©rente, mais il se peut tout √† fait qu'un individu sur le spectre ait une amygdale plus grande qu'un individu neurotypique.

Plut√¥t que de seulement se fier √† la significativit√©, il est important de mesurer la taille de
l'effet, c'est-√†-dire la diff√©rence qui existe entre les deux populations. On peut par exemple consid√©rer la diff√©rence des moyennes que l'on divise ensuite par l'√©cart type des deux populations - une mesure appel√©e le _d_ de Cohen. Un _d_ de Cohen de 0.1 ou 0.2 est courant pour des diff√©rences de groupes entre populations cliniques. Avec ce type de diff√©rence, les distributions des deux groupes se chevauchent de mani√®re importante. Un _d_ de Cohen de 2 d√©crirait pour sa part un effet de groupe tr√®s important, o√π le score de presque tous les membres d‚Äôun groupe est inf√©rieur au score de tous les membres de l‚Äôautre groupe.

```{admonition} Valeur _p_ et taille d'effet
:class: caution attention
:name: p-value-warning

La valeur _p_ ne nous donne aucune information directe sur la taille de l'effet. Une valeur _p_ peut √™tre tr√®s significative, par exemple _p<0.000001_ simplement parce que l'on compare deux groupes ayant une tr√®s grande taille d'√©chantillon, par exemple N=10000 par groupe. Dans ce cas, m√™me de toutes petites diff√©rences peuvent devenir tr√®s significatives.
```

### M√©thodes incompl√®tes
```{figure} ./reproductibilite/machine_learning.png
---
width: 400px
name: machine-learning-fig
---
Cette figure illustre le processus parfois chaotique de d√©veloppement d'une m√©thode optimale et la difficult√© de communiquer ce processus de mani√®re claire et compl√®te dans la section de m√©thodes d'un article. Cette figure est tir√©e de [xkcd webcomic](https://xkcd.com/1838/), sous licence [CC-BY-NC 2.5](https://creativecommons.org/licenses/by-nc/2.5/).
```
Le manque de d√©tails dans la section "M√©thodes" d'un article peut √™tre un autre obstacle majeur √† la reproduction des r√©sultats. Comme les techniques d'analyse utilis√©es en neuroimagerie sont souvent complexes, il est tr√®s rare d'avoir une description compl√®te des m√©thodes. Il est aussi courant de mettre les √©tapes qui ont amen√© √† la s√©lection des m√©thodes utilis√©es dans l'article. Le texte d'un article scientifique est g√©n√©ralement √©crit de mani√®re √† raconter une histoire claire. Le mat√©riel suppl√©mentaire de l'article contient parfois (mais pas toujours) plus de d√©tails m√©thodologiques ainsi que des exp√©riences suppl√©mentaires, non essentielles au narratif principal de l'article. Il est tout √† fait possible que d'autres analyses soient omises enti√®rement de l'article et que les membres de l'√©quipe de recherche soient eux-m√™mes incapables de retracer le processus qui a amen√© √† la s√©lection des analyses finales publi√©es dans l'article.

## Des solutions

### √âtudes pr√©-enregistr√©es
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]

import seaborn as sns
import matplotlib.pyplot as plt
sns.set_theme(style="whitegrid")

# donn√©es de https://psyarxiv.com/3czyt
negative_findings = pd.DataFrame({
    'source':['articles', 'nouvelles √©tudes pr√©-enregistr√©es', 'r√©plications pr√©-enregistr√©es'],
    '%min':[5, 55, 58],
    '%max':[20, 66, 74]
    })

# Initialise la figure
fig, ax = plt.subplots(figsize=(6, 4))
print('test')
# Estimation maximale
sns.set_color_codes("pastel")
sns.barplot(x="%max", y="source", data=negative_findings,
            label="%max", color="b")

# Estimation minimale
sns.set_color_codes("muted")
sns.barplot(x="%min", y="source", data=negative_findings,
            label="%min", color="b")

# L√©gende
ax.legend(ncol=2, loc="upper right", frameon=True)
ax.set(xlim=(0, 100), ylabel="",
       xlabel="Pourcentage de d√©couvertes n√©gatives dans la litt√©rature")
sns.despine(left=True, bottom=True)
fig.set_dpi(300)

from myst_nb import glue
glue("registered-report-fig", fig, display=False)
```
```{glue:figure} registered-report-fig
:figwidth: 600px
:name: registered-report-fig
Pourcentage de "d√©couvertes n√©gatives" dans la litt√©rature. Les d√©couvertes n√©gatives viennent d'√©tudes pour lesquelles les analyses ne confirment pas les hypoth√®ses de recherche. On compare ici des articles traditionnels avec des √©tudes pr√©-enregistr√©es portant sur de nouvelles hypoth√®ses de recherche, ainsi que des √©tudes pr√©-enregistr√©es portant sur des √©tudes de r√©plication de r√©sultats d√©j√† publi√©s. Pour chaque pourcentage, une valeur estim√©e minimale et maximale est fournie. Statistiques tir√©es de [Allen et Mehler, 2018](https://doi.org/10.31234/osf.io/3czyt) sur 127 √©tudes pr√©-enregistr√©es. Figure g√©n√©r√©e avec du code python √† l'aide de la librairie [seaborn](https://seaborn.pydata.org/) (cliquer sur + pour voir le code). Cette figure produite par P. Bellec est distribu√©e sous licence [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```


Une premi√®re id√©e qui gagne en popularit√© pour r√©pondre √† la crise de la reproductibilit√© est ce que l'on appelle une **√©tude pr√©-enregistr√©e**. Un des probl√®mes dans le cercle pr√©sent√© en {numref}`researchcycle-original-fig`, c‚Äôest qu‚Äôon choisit de ne publier que quand on conna√Æt les r√©sultats. Comme publier un article est un processus long et co√ªteux (certains journaux demandent plusieurs milliers de dollars de frais de publication) et que les r√©sultats n√©gatifs sont peu valoris√©s, il est compr√©hensible que l'√©quipe de recherche d√©cide simplement de passer au prochain projet plut√¥t qu'investir dans la publication d'un r√©sultat n√©gatif. Une mani√®re d‚Äô√©liminer √ßa,
c‚Äôest de soumetre la publication avec les hypoth√®ses et les plans d‚Äôanalyse, avant de recueillir les donn√©es. Cela permet aux
reviewers de critiquer la conception de l‚Äô√©tude avant qu‚Äôelle soit termin√©e, et permet donc de modifier le protocole de recherche si n√©cessaire. L'article est alors accept√©, _quelque soit le r√©sultat de l'√©tude_. Si les
r√©sultats ne correspondent pas aux hypoth√®ses, l‚Äôarticle
serait d√©j√† accept√© et publi√© tout de m√™me. Cela ne veut pas dire qu‚Äôon ne
peut pas pr√©senter des nouvelles analyses auxquelles on n‚Äôavait pas pens√©
avant. Celles-ci sont alors pr√©sent√©es (correctement) comme exploratoires, plut√¥t que confirmatoires. En d'autres termes, cette approche √©limine le HARKing, et il semble en pratique que cette approche fonctionne (voir {numref}`registered-report-fig`).

### Code
```{figure} ./reproductibilite/python.png
---
width: 600px
name: python-fig
---
Cette figure illustre les avantages d'automatiser les analyses scientifiques √† l'aide de code (de mani√®re m√©taphorique). Cette figure est tir√©e de [xkcd webcomic](https://xkcd.com/353/), sous licence [CC-BY-NC 2.5](https://creativecommons.org/licenses/by-nc/2.5/).
```
Une autre solution pour rendre les analyses scientifiques en neuroimagerie plus reproductible est d'apprendre √† coder. Automatiser les analyses permet de les rendre plus faciles √† reproduire pour quiconque. Il peut y avoir des erreurs dans le code, mais elles peuvent √™tre vues et r√©par√©es par d'autres. Les analyses qui ne reposent pas sur du code repr√©sentent un obstacle majeur √† la reproductibilit√©. Pour √™tre vraiment utile, le code d'une analyse doit √™tre partag√© publiquement. Ce code constitue alors un artefact de recherche tr√®s important, beaucoup plus d√©taill√© et sp√©cifique que la section m√©thodologique d'un article. Beaucoup de gens utilisent la plateforme [Github](https://github.com/) pour partager des √©l√©ments de code et aussi afin de partager les modifications qui y sont faites avec le temps. Il est aussi possible d'archiver une version du code sur une plateforme comme [zenodo](https://zenodo.org/) qui fournit un identifiant unique pour ce code, comme pour un article. Si le code est de haute qualit√© et r√©utilisable, il est m√™me possible de publier un article sur ce code dans un journal comme le [Journal of Open Source Software](https://joss.theoj.org/).

### Partage de donn√©es
```{figure} ./reproductibilite/openneuro-downloads.jpg
---
width: 600px
name: openneuro-downloads-fig
---
Nombre de jeux de donn√©es ouverts en neuroimagerie et nombre de participants disponibles sur la plateforme de partage de donn√©es [openneuro](https://openneuro.org/). Figure tir√©e de [Markiewicz et al., 2021](https://doi.org/10.7554/eLife.71774) sous licence [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
Une autre solution pour am√©liorer la reproducibilit√© est de partager les donn√©es de recherche. La {numref}`openneuro-downloads-fig` illustre l'adoption rapide de cette pratique dans la communaut√© de recherche en neuroimagerie. Partager ses donn√©es permet √† d'autres laboratoires de r√©pliquer les analyses ou essayer d'autres m√©thodes. Cela permet aussi au laboratoire d'origine de disposer d'une archive bien organis√©e pour de futurs projets. Le partage des donn√©es humaines est en revanche rendu complexe dans certaines parties du monde (comme le Qu√©bec) √† cause de consid√©rations √©thiques ou bien l√©gales. Il est en revanche toujours possible de partager des cartes statistiques de groupe, par exemple en utilisant une plateforme comme [neurovault](https://neurovault.org/).

### Partage d'environnement
Des outils existent √©galement pour partager un environnement de travail, ce qui est possible gratuitement gr√¢ce aux technologies libres. Il existe diverses solutions. Le language `python` permet de d√©crire un ensemble de d√©pendances (avec versions) au moyen d'un simple fichier texte `requirements.txt`. Certaines versions de linux comme [neurodebian](https://neuro.debian.net/) ont √©galement un grand nombre d'outils de neuroimagerie pr√™ts √† l'installation, incluant des fonctionnalit√©s de contr√¥le des versions. Les `containers` sont une autre famille de solutions qui permettent de partager un ensemble de librairies ainsi que le syst√®me d'exploitation. Des variantes de `containers` ont √©t√© sp√©cifiquement d√©velopp√©es pour les neurosciences cognitives, comme [neurodocker](https://www.repronim.org/neurodocker/). Un dernier exemple est [mybinder](https://mybinder.org/) qui permet d'importer un `container` avec toutes les d√©pendances d'un projet et de r√©-ex√©cuter ce code dans un fureteur internet, sans avoir √† installer quoi que ce soit. Pour la version en ligne de ces notes de cours, il y a une petite fus√©e en haut √† droite qui d√©marre la plateforme mybinder. Comme les notes de cours utilisent des donn√©es ouvertes pour beaucoup de figures, il est possible de reproduire (et modifier) les figures du cours de cette mani√®re.

### Puissance statistique et meilleures pratiques

Certains articles se concentrent sur la formulation de ¬´ guides ¬ª des meilleures
pratiques pour diff√©rentes m√©thodes de recherche. Le domaine des neurosciences cognitives a par exemple un guide baptis√© COBIDAS [(Nichols et al., 2017)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5685169/), qui a √©galement une version pour la MEG [(Pernet et al., 2020)](https://osf.io/a8dhx/). Ce type de guide permet de s√©lectionner des m√©thodes qui sont non seulement reproductibles, mais id√©alement aussi robustes et pourront √™tre r√©pliqu√©es avec des m√©thodes ou des donn√©es diff√©rentes. Un point important √† consid√©rer est celui de la **puissance statistique** d'une √©tude. Alors que la valeur _p_ nous informe sur la fr√©quence de faux positifs, c'est-√†-dire une d√©tection faite en l'absence de signal, la puissance statistique nous informe sur la fr√©quence des faux n√©gatifs, c'est-√†-dire le signal qu'on n'arrive pas √† d√©tecter. Pour qu'un r√©sultat soit reproductible, il est critique que la puissance statistique du test soit √©lev√©e. Avec le mod√®le lin√©aire g√©n√©ral, la puissance statistique d√©pend de la taille d'effet, du nombre de participants dans l'√©tude ainsi que du taux de faux positifs _p_ du test. Voir cette [page internet](https://rpsychologist.com/d3/nhst/) pour exp√©rimenter avec diff√©rents param√®tres.

## Conclusions
```{figure} ./reproductibilite/research-cycle.jpg
---
width: 800px
name: research-cycle-fig
---
Un cycle de d√©couvertes en recherche qui inclut la pr√©servation et la r√©utilisation des donn√©es. Figure par [scriberia](https://info.scriberia.com/contact-us) dans le cadre du livre [The Turing way](https://the-turing-way.netlify.app) sous licence [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/), DOI: [10.5281/zenodo.3332807](https://doi.org/10.5281/zenodo.3332807).
```
Dans ce chapitre, on a vu:
 * certaines pratiques de recherche douteuses qui peuvent amener √† des d√©couvertes scientifiques non-reproductibles.
 * des aspects de la recherche en neuroimagerie qui sont particuli√®rement probl√©matiques:
   * sensibilit√© √† de nombreux param√®tres
   * manque de quantification des tailles d'effet
   * difficult√©s √† d√©crire les m√©thodes de mani√®re compl√®te dans un article.
 * des nouvelles pratiques qui permettent d'am√©liorer la reproductibilit√© de la science:
   * √©tudes pr√©-enregistr√©es
   * partage de code, donn√©es et environnement
   * meilleures pratiques d'analyse.

On voit aujourd'hui √©merger une nouvelle approche de d√©couverte scientifique qui inclut notamment le partage et la r√©utilisation de donn√©es, ce qui va amener une science plus reproductible et fiable ({numref}`research-cycle-fig`).

## Exercices
```{admonition} Exercice 1
:class: note
Vrai/faux. La significativit√© des r√©sultats dans une √©tude de neuroimagerie peut √™tre impact√©e par...
 1. le logiciel que l‚Äôon utilise pour tester l‚Äôhypoth√®se de recherche.
 2. les param√®tres que l‚Äôon choisit pour analyser les donn√©es, comme par exemple la quantit√© de lissage spatial.
 3. le syst√®me d‚Äôexploitation de l‚Äôordinateur utilis√© pour effectuer les analyses.
 4. la version du syst√®me d‚Äôexploitation de l‚Äôordinateur utilis√© pour effectuer les analyses.
```

```{admonition} Exercice 2
:class: note
Vrai/faux. La puissance statistique...
 1. indique la probabilit√© de d√©tecter un effet avec une proc√©dure statistique.
 2. contr√¥le le taux de faux positifs.
 3. d√©cro√Æt avec le nombre de sujets dans l‚Äô√©tude.
 4. cro√Æt avec le seuil de significativit√© choisi pour l‚Äô√©tude (seuil p).
 5. d√©cro√Æt avec la taille de l‚Äôeffet test√©.
```

```{admonition} Exercice 3
:class: note
Choisissez la bonne r√©ponse.
Pour pouvoir reproduire exactement un r√©sultat de recherche, il est n√©cessaire d‚Äôavoir acc√®s...
  1. aux donn√©es utilis√©es dans l‚Äô√©tude
  2. au code utilis√© pour g√©n√©rer les r√©sultats de l‚Äô√©tude, s‚Äôil existe
  3. √† l‚Äôenvironnement (version des logiciels) utilis√© dans l‚Äô√©tude
  4. R√©ponses 1 et 2.
  5. R√©ponses 1, 2 et 3.
```

```{admonition} Exercice 4
:class: note
Choisissez la bonne r√©ponse.
Parmi les proc√©dures suivantes, laquelle (lesquelles) n'est (ne sont) pas statistiquement valide(s)?
 1. Pr√©senter comme hypoth√®se d‚Äôune √©tude une observation faite seulement apr√®s l'obtention et l'analyse des donn√©es.
 2. Red√©finir les crit√®res d‚Äôexclusion des participants en se basant sur la qualit√© des donn√©es, et ce, apr√®s avoir effectu√© une premi√®re analyse des donn√©es.
 3. Pr√©senter dans une √©tude uniquement les r√©sultats d‚Äôun sous-groupe du devis de recherche original parce que ce sous-groupe est le seul qui pr√©sente des r√©sultats significatifs.
 4. Aucune des trois proc√©dures pr√©sent√©es ci-haut n‚Äôest valide.
 5. R√©ponses 2 et 3.
```

```{admonition} Exercice 5
:class: note
Une √©quipe de recherche a effectu√© une √©tude par activation en imagerie optique chez des nouveaux-n√©s. Le comit√© d‚Äô√©thique n‚Äôa pas permis le partage des donn√©es de recherche. Proposez deux actions concr√®tes pour am√©liorer malgr√© tout la reproductibilit√© de l‚Äô√©tude.
```

```{admonition} Exercice 6
:class: note
Une √©quipe de recherche compare le volume de diff√©rentes r√©gions du cerveau entre deux groupes de sujets (N=20 par groupe): des sujets en sant√© ainsi que des sujets pr√©sentant des signes de d√©pression. Pour cela, l‚Äô√©quipe effectue une analyse par volum√©trie automatis√©e utilisant un atlas comprenant 90 r√©gions et teste l‚Äôeffet de groupe sur chaque r√©gion ind√©pendamment avec un mod√®le de r√©gression qui inclut l‚Äô√¢ge et le sexe des participants. Le seuil de significativit√© est fix√© √† p<0.05. Le seul test significatif est identifi√© au niveau de l‚Äôamygdale (p=0.041). La conclusion de l‚Äô√©tude est ‚ÄúLe volume de l‚Äôamygdale est plus petit chez les individus pr√©sentant des signes de d√©pression, mais le volume de l‚Äôhippocampe est normal‚Äù. Identifiez trois probl√®mes majeurs avec cette conclusion.    
```
