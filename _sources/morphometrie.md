---
jupytext:
  cell_metadata_filter: -all
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.10.3
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---
(morphometrie-chapitre)=
# Analyses morphom√©triques

<table>
  <tr>
    <td align="center">
      <a href="https://github.com/eddyfortier">
        <img src="https://avatars.githubusercontent.com/u/72314243?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>Eddy Fortier</b></sub>
      </a>
      <br />
        <a title="Contenu">ü§î</a>
        <a title="R√©vision du texte">üëÄ</a>
    </td>
    <td align="center">
      <a href="https://github.com/me-pic">
        <img src="https://avatars.githubusercontent.com/u/77584086?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>Marie-Eve Picard</b></sub>
      </a>
      <br />
        <a title="R√©vision du texte">üëÄ</a>
    </td>
    <td align="center">
      <a href="https://github.com/pbellec">
        <img src="https://avatars.githubusercontent.com/u/1670887?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>Pierre bellec</b></sub>
      </a>
      <br />
        <a title="Contenu">ü§î</a>
        <a title="Quizz">‚ö†Ô∏è</a>
        <a title="R√©vision du texte">üëÄ</a>
        <a title="Code">üíª</a>
        <a title="Quiz">‚ö†Ô∏è</a>
    </td>
  </tr>
</table>

## Objectifs du cours

Ce cours introduit diff√©rentes approches pour quantifier la morphologie du cerveau √† l'aide des donn√©es d'imagerie par r√©sonance magn√©tique anatomique. Il sera question dans ce chapitre de trois grandes approches d'analyse:
 * la **volum√©trie**, qui vise √† mesurer la taille d'une r√©gion c√©r√©brale;
 * la **morphom√©trie bas√©e sur les voxels (*voxel-based morphometry* ou VBM)**, qui vise √† mesurer le volume de mati√®re grise locale pour chaque voxel dans le cerveau;
 * les **analyses de surface**, qui exploitent la structure en ruban de la mati√®re grise pour mesurer l'√©paisseur et la surface corticale.

On parlera √©galement d'√©tapes d'analyse d'images utiles pour l'ensemble de ces techniques: le **recalage**, la **segmentation**, le **lissage** et le **contr√¥le de qualit√©**.

## Morphom√©trie

```{figure} ./morphometrie/morphometrie_durer.jpg
---
width: 600px
name: morphometrie-durer-fig
---
√âtude de D√ºrer sur les proportions du visage.
Image appartenant au domaine public, tir√©e de [wikimedia](https://commons.wikimedia.org/wiki/File:Morpho_durer.JPG).
```

En neurosciences, la [morphom√©trie](https://fr.wikipedia.org/wiki/Morphom%C3%A9trie) est l'√©tude de la forme du cerveau et de ses structures.
Le terme morphom√©trie combine deux termes tir√©s du grec ancien: *morphos* (forme) et *m√©tron* (mesure).
La morphom√©trie est donc la "mesure" de la "forme".
Pour mesurer la forme du cerveau, il est n√©cessaire de pouvoir observer clairement les d√©limitations neuroanatomiques.
L'IRM anatomique nous donne un bon contraste entre mati√®re grise, mati√®re blanche et liquide c√©phalo-rachidien.
Combin√©e avec des outils automatiques d'analyse d'images, l'IRM permet donc de r√©aliser des √©tudes de morphologie computationnelle.

```{figure} ./morphometrie/ledig2018.webp
---
width: 600px
name: ledig2018-fig
---
Cette figure illustre des diff√©rences morphologiques entre des individus pr√©sentant des profils cliniques diff√©rents: sans atteinte cognitive (haut), troubles l√©gers de la cognition (milieu), d√©mence de type Alzheimer (bas).
Par ailleurs, il est √©galement possible d'observer des diff√©rences longitudinales au sein d'un m√™me individu (de gauche √† droite, visite initiale, suivi apr√®s deux ans, diff√©rence entre les deux images).
Figure tir√©e de {cite:p}`Ledig2018-ai`, sous licence CC-BY.
```

Comme le d√©montre la figure ci-haut, les √©tudes morphologiques IRM permettent de comparer des individus et des groupes.
De telles comparaisons peuvent nous informer sur l'effet de l'√¢ge, ou bien encore l'effet d'une l√©sion ou d'une maladie sur la forme du cerveau.

## Volum√©trie

### Segmentation manuelle

```{figure} ./morphometrie/ashempour2019.jpg
---
width: 600px
name: ashempour2019-fig
---
Cette figure illustre un protocole de segmentation manuelle de l'amygdale.
Vue coronale d'une segmentation manuelle de l'amygdale gauche (jaune) et droit (bleu) avant (gauche) et apr√®s (droite) avoir proc√©d√© aux corrections dans le plan coronal.
Figure tir√©e de {cite:p}`Hashempour2019-jq`, sous licence CC-BY.
```

La **volum√©trie manuelle** consiste √† d√©limiter visuellement une aire c√©r√©brale particuli√®re, comme l'hippocampe ou l'amygdale (voir {numref}`ashempour2019-fig`).
Cette approche n√©cessite du temps, car le contour des structures d'int√©r√™t doit √™tre dessin√© √† la main sur chaque coupe d'IRM.
On commence d'abord par segmenter une structure dans un premier plan de coupe (par exemple, dans le plan axial), puis il faudra aller corriger cette segmentation dans les autres plans (par exemple, dans le plan sagittal, puis dans le plan coronal).

> Pour un rappel concernant les diff√©rents types de coupes du cerveau, veuillez vous r√©f√©rer au [Chapitre 1: Cartes c√©r√©brales](<coupes-tip>).

Afin de d√©terminer o√π une r√©gion c√©r√©brale se situe, ce type d'approche n√©cessite √©galement un protocole de segmentation avec des crit√®res anatomiques clairs.
Pour certaines structures, comme pour l'hippocampe, il existe des protocoles d√©taill√©s (par exemple: {cite:p}`Wisse2017-ff`).
Mais pour d'autres r√©gions, comme les aires visuelles (V1, V2, etc.), il est n√©cessaire de r√©aliser des exp√©riences fonctionnelles afin de pouvoir les d√©limiter.
En effet, dans ce dernier cas, les d√©limitations anatomiques ne sont pas toujours disponibles ou bien √©tablies.

Un protocole de segmentation rigoureux est n√©cessaire pour obtenir un bon niveau de [concordance](https://en.wikipedia.org/wiki/Inter-rater_reliability) des r√©sultats entre diff√©rents chercheurs (accord inter-juges).
Certains protocoles proposent aussi un processus de certification, ce qui offre une garantie que la personne effectuant la segmentation applique le protocole correctement.

### Segmentation automatique

```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]

# T√©l√©chargement de l'atlas Harvard-Oxford
from nilearn import datasets

# Enl√®ve les warnings
import warnings
warnings.filterwarnings("ignore")

atlas = datasets.fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm').maps
mni = datasets.fetch_icbm152_2009()

# Visualisation de la figure
import matplotlib.pyplot as plt
from myst_nb import glue
from nilearn import plotting

fig = plt.figure(figsize=(12, 4))
plotting.plot_roi(atlas,
    bg_img=mni.t1,
    axes=fig.gca(),
    title="Atlas Harvard-Oxford",
    cut_coords=(8, -4, 9),
    colorbar=True,
    cmap='Paired')

glue("harvard-oxford-fig", fig, display=False)
```

```{glue:figure} harvard-oxford-fig
:figwidth: 800px
:name: "harvard-oxford-fig"

Un exemple d'atlas de r√©gions anatomiques: l'atlas Harvard-Oxford.
Cette figure est g√©n√©r√©e par du code python √† l'aide de la librairie [nilearn](https://nilearn.github.io/) √† partir d'un jeu de donn√©es public appel√© fetch_atlas_harvard_oxford ([Nilearn, section 9.2.1: Basic Atlas plotting](https://nilearn.github.io/auto_examples/01_plotting/plot_atlas.html)) {cite:p}`MAKRIS2006155, Frazier2005, DESIKAN2006968, GOLDSTEIN2007935` (cliquer sur + pour voir le code).
```

Afin d'automatiser le travail de segmentation, il est possible d'utiliser un atlas, c'est-√†-dire une segmentation d√©j√† effectu√©e par une √©quipe de chercheurs.
Pour ce faire, ceux-ci ont construit une carte des r√©gions d'int√©r√™t √† l'int√©rieur d'un espace de r√©f√©rence, aussi appel√© {ref}`espace st√©r√©otaxique <stereotaxique-tip>`.
Il existe une vari√©t√© d'atlas bas√©s sur diff√©rents crit√®res anatomiques ou fonctionnels, il est donc important de choisir ad√©quatement l'atlas en fonction des structures √©tudi√©es.
Afin d'ajuster l'atlas sur les donn√©es d'un participant, les images structurelles de ce dernier sont d'abord {ref}`recal√©es <registration-tip>` de mani√®re automatis√©e vers l'{ref}`espace st√©r√©otaxique <stereotaxique-tip>` de r√©f√©rence.
Cette transformation permet par la suite d'adapter l'atlas √† l'anatomie de chaque sujet.

```{admonition} Le recalage
:class: tip
:name: registration-tip

Afin d'appliquer un atlas de r√©gions c√©r√©brales sur une IRM individuelle, ou plus g√©n√©ralement mettre en correspondance deux images de cerveaux, il est n√©cessaire de recaler cette IRM sur l'espace st√©r√©otaxique qui a √©t√© utilis√© pour √©tablir les r√©gions.
Ce processus math√©matique va chercher √† d√©former l'image individuelle afin de l'ajuster √† l'espace st√©r√©otaxique.
Cette transformation peut √™tre affine (incluant notamment translation, rotation et mise √† l'√©chelle) ou bien non-lin√©aire (d√©placement dans n'importe quelle direction de l'espace).
L'objectif du recalage est d'augmenter le niveau de similarit√© entre les images, mais il est aussi important que les d√©formations soient continues.
Autrement dit, des endroits adjacents dans les images non-recal√©es doivent toujours √™tre adjacents apr√®s le recalage.
Les images ci-dessous illustrent l'effet de diff√©rents types de recalage.
Elles sont tir√©es de la documentation du logiciel [slicer](https://www.slicer.org/wiki/Documentation:Nightly:Registration:RegistrationLibrary:RegLib_C42), sous licence CC-Attributions Share Alike.

```{figure} morphometrie/registration_slicer_raw.gif
:figwidth: 400px
:align: left
Images brutes: deux scans du m√™me sujet, prises durant deux s√©ances d'acquisition diff√©rentes.

```{figure} morphometrie/registration_slicer_affine.gif
:figwidth: 400px
:align: left
:figclass: margin-caption
Images recal√©es par un processus de transformation affine seulement.

```{figure} morphometrie/registration_slicer_nonlinear.gif
:figwidth: 400px
:align: left
:figclass: margin-caption
Images recal√©es par une transformation affine suivie d'une transformation non-lin√©aire.

```{figure} morphometrie/registration_slicer_nonlinear_only.gif
:figwidth: 400px
:align: left
:figclass: margin-caption
Visualisation des effets du recalage non-lin√©aire seulement.
```

```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
# Ce code r√©cup√®re des donn√©es IRM T1
# et g√©n√®re une image dans trois plans de coupes

# Enl√®ve les warnings
import warnings
warnings.filterwarnings("ignore")

# T√©l√©charge un scan anatomique (template MNI152)
from nilearn.datasets import fetch_icbm152_2009
mni = fetch_icbm152_2009()

# Visualise le volume c√©r√©bral
import matplotlib.pyplot as plt
from myst_nb import glue
from nilearn.plotting import plot_anat

fig = plt.figure(figsize=(12, 4))
plot_anat(
  mni.t1,
  axes=fig.gca(),
  cut_coords=[-17, 0, 17],
  title='Espace stereotaxique MNI152'
)
glue("mni-template-fig", fig, display=False)
```

```{admonition} Espace st√©r√©otaxique
:class: tip
:name: stereotaxique-tip

Afin de d√©finir une anatomie de r√©f√©rence, les chercheurs utilisent g√©n√©ralement un cerveau "moyen".
Pour y parvenir, les cerveaux de plusieurs dizaines d'individus sont recal√©s les uns avec les autres, puis moyenn√©s jusqu'√† obtenir une seule image.
Si le recalage a bien fonctionn√©, comme dans le cas de l'atlas MNI152 ci-dessous, les d√©tails de la neuroanatomie sont pr√©serv√©s dans la moyenne.
```{glue:figure} mni-template-fig
:figwidth: 600px
:align: left
Espace st√©r√©otaxique de l'Institut Neurologique de Montr√©al (MNI).
Cette espace de r√©f√©rence a √©t√© obtenu en faisant la moyenne des images c√©r√©brales de 152 sujets apr√®s avoir proc√©d√© √† un recalage non-lin√©aire it√©ratif {cite:p}`Fonov2011-xr`.
```

### Analyses statistiques
```{figure} ./morphometrie/ledig2018_stats.png
---
width: 400px
name: ledig2018-stats-fig
---
Cette figure illustre les diff√©rences de volume de l'hippocampe entre des participants cognitivement sains (HC), des participants pr√©sentant des troubles cognitifs l√©gers stables (sMCI) ou progressifs (pMCI), ainsi que des patients atteints d'une d√©mence de type Alzheimer (AD), dans la cohorte ADNI.
Plus les sympt√¥mes cliniques sont s√©v√®res, plus la probabilit√© de pr√©senter la maladie d'Alzheimer est grande, et plus le stade d'avancement de la maladie est s√©v√®re.
L'atrophie de l'hippocampe est claire chez les patients pr√©sentant les sympt√¥mes les plus s√©v√®res.
Figure tir√©e de {cite:p}`Ledig2018-ai`, sous licence CC-BY.
```
Afin de proc√©der aux analyses statistiques, on extrait d'abord le volume de chaque structure segment√©e (en $mm^3$).
On peut ensuite comparer statistiquement le volume moyen entre deux groupes, par exemple, ou encore tester l'association entre le volume et une autre variable, comme l'√¢ge.
Dans l'exemple de la {numref}`ledig2018-stats-fig`, on compare le volume de l'hippocampe entre diff√©rents groupes cliniques ayant diff√©rents niveaux de risques li√©s √† la maladie d'Alzheimer.

### Contr√¥le de qualit√©
```{figure} ./morphometrie/artefact-fig.png
---
width: 600px
name: artefact-fig
---
La pr√©sence de m√©tal ou d'√©l√©ments d√©fectueux dans le scanner peuvent causer des artefacts et des distorsions dans les images qui ne refl√®tent pas la morphologie r√©elle de la t√™te.
Figure d'origine inconnue, possiblement sous droits r√©serv√©s.
```
```{figure} ./morphometrie/qc-fail-fig.png
---
width: 600px
name: qc-fail-fig
---
Le recalage peut parfois √©chouer de mani√®re spectaculaire.
Ici, la forme rouge indique le pourtour attendu du cerveau et de certains rep√®res anatomiques.
L'IRM individuelle recal√©e n'est pas du tout align√©e avec les rep√®res attendus.
Figure par P. Bellec, sous licence CC-BY.
```

Il est possible d'obtenir des r√©sultats aberrants en volum√©trie, soit √† cause de la pr√©sence d'erreurs dans les √©tapes de recalage lin√©aire et/ou non-lin√©aire ({numref}`qc-fail-fig`), soit √† cause d'artefacts lors de l'acquisition des donn√©es (pr√©sence d'objets m√©talliques, etc. {numref}`artefact-fig`). Les images peuvent √©galement √™tre de mauvaise qualit√© si le sujet de recherche bouge pendant l'acquisition.
Il est important d'effectuer un contr·ªìle de qualit√© afin d'√©liminer les images inutilisables avant de proc√©der aux analyses statistiques.
Conserver ces derni√®res pourrait avoir des impacts importants sur les r√©sultats ainsi que sur les conclusions tir√©es.

## VBM

### Densit√© de mati√®re grise
La morphom√©trie bas√©e sur les voxels (*voxel-based morphometry* ou VBM) a pour objectif de mesurer le volume de mati√®re grise situ√© imm√©diatement autour d'un voxel donn√©.
Cette approche n'est donc pas limit√©e par le besoin d'avoir des fronti√®res pr√©√©tablies claires entre diff√©rentes structures c√©r√©brales.
Lorsque l'on g√©n√®re une mesure de volume pour l'ensemble des voxels du cerveau √† l'aide de ce genre de technique, on obtient une carte 3D de la densit√© de la mati√®re grise.
Les principaux avantages de cette approche sont ses aspects automatis√©s et syst√©matiques.
La pr√©sence d'une personne ne devient n√©cessaire que pour v√©rifier que la proc√©dure a fonctionn√© correctement: c'est l'√©tape du contr√¥le de qualit√© (ou QC, pour "quality control").
On va aussi tester la morphologie du cerveau √† travers l'ensemble de la mati√®re grise.
D'un autre c√¥t√©, cette technique comporte aussi un inconv√©nient important.
En effet, le grand nombre de mesures g√©n√©r√©es pose un probl√®me de _comparaisons multiples_ lorsque vient le temps de faire les analyses statistiques (voir le [Chapitre 9: Cartes statistiques](cartes-statistiques-chapitre)).

### Segmentation
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
# Importe les librairies n√©cessaires
import matplotlib.pyplot as plt
import numpy as np
from myst_nb import glue
import seaborn as sns

import warnings
warnings.filterwarnings("ignore")

# T√©l√©charge un scan anatomique (template MNI152)
from nilearn import datasets
mni = datasets.fetch_icbm152_2009()

# Initialise la figure
fig = plt.figure(figsize=(15, 15))

from nilearn.plotting import plot_stat_map
from nilearn.image import math_img
from nilearn.input_data import NiftiMasker

thresh = 0.8
coords = [-5, 5, -25]

# Full brain
ax_plot = plt.subplot2grid((4, 3), (0, 0), colspan=1)
mask_brain = math_img(f"img>{thresh}", img=mni.mask)
val_brain = NiftiMasker(mask_img=mask_brain).fit_transform(mni.t1)
ax = sns.distplot(val_brain, norm_hist=False)
ax.set_xlim(left=0, right=100)
ax_plot = plt.subplot2grid((4, 3), (0, 1), colspan=2)
plot_stat_map(mni.mask,
              bg_img=mni.t1,
              cut_coords=coords,
              axes=ax_plot,
              black_bg=True,
              title='Cerveau'
              )

# Gray matter
ax_plot = plt.subplot2grid((4, 3), (1, 0), colspan=1)
mask_gm = math_img(f"img>{thresh}", img=mni.gm)
val_gm = NiftiMasker(mask_img=mask_gm).fit_transform(mni.t1)
ax = sns.distplot(val_gm, norm_hist=False)
ax.set_xlim(left=0, right=100)
ax_plot = plt.subplot2grid((4, 3), (1, 1), colspan=2)
plot_stat_map(mni.gm,
              bg_img=mni.t1,
              cut_coords=coords,
              axes=ax_plot,
              black_bg=True,
              title='Mati√®re grise'
              )

# White matter
ax_plot = plt.subplot2grid((4, 3), (2, 0), colspan=1)
mask_wm = math_img(f"img>{thresh}", img=mni.wm)
val_wm = NiftiMasker(mask_img=mask_wm).fit_transform(mni.t1)
ax = sns.distplot(val_wm, norm_hist=False)
ax.set_xlim(left=0, right=100)
ax_plot = plt.subplot2grid((4, 3), (2, 1), colspan=2)
plot_stat_map(mni.wm,
              bg_img=mni.t1,
              cut_coords=coords,
              axes=ax_plot,
              black_bg=True,
              title='Mati√®re blanche'
              )

# CSF
ax_plot = plt.subplot2grid((4, 3), (3, 0), colspan=1)
mask_csf = math_img(f"img>{thresh}", img=mni.csf)
val_csf = NiftiMasker(mask_img=mask_csf).fit_transform(mni.t1)
ax = sns.distplot(val_csf, axlabel="intensit√© de l'image", norm_hist=False)
ax.set_xlim(left=0, right=100)
ax_plot = plt.subplot2grid((4, 3), (3, 1), colspan=2)
plot_stat_map(mni.csf,
              bg_img=mni.t1,
              cut_coords=coords,
              axes=ax_plot,
              black_bg=True,
              title='Liquide c√©phalo-rachidien'
              )

from myst_nb import glue
glue("mni-segmentation-fig", fig, display=False)
```
```{glue:figure} mni-segmentation-fig
:figwidth: 600px
:name: mni-segmentation-fig
Segmentation probabiliste des principaux types de tissus et distribution des valeurs pond√©r√©es en T1 dans les voxels "purs" (probabilit√© sup√©rieure √† 80% pour un type de tissu donn√©).
L'image pond√©r√©e en T1 ainsi que les segmentations correspondent √† l'espace st√©r√©otaxique MNI152 {cite:p}`Fonov2011-xr`.
```

Une √©tape importante de la VBM est la segmentation.
Cette analyse vise √† cat√©goriser les types de tissus du cerveau en diff√©rentes classes contenant notamment la mati√®re grise, la mati√®re blanche et le liquide c√©phalo-rachidien.
Un masque du cerveau est g√©n√©ralement extrait afin d'exclure les m√©ninges ainsi que le cr√¢ne.
On va g√©n√©ralement y inclure d'autres types de tissus √©galement, comme la graisse.
Un algorithme de segmentation va ensuite examiner la distribution des niveaux de gris dans l'image (par exemple, dans une image pond√©r√©e en T1) et estimer pour chaque voxel la proportion du voxel qui contient un type de tissu donn√©.
Cette proportion est souvent appel√© l'{ref}`effet de volume partiel <volume-partiel-tip>`.
Un voxel peut par exemple √™tre assign√© √† 80% de mati√®re grise et 20% de liquide c√©phalo-rachidien.
Le niveau de gris r√©sultant pourrait alors donner une indication trompeuse sur son contenu r√©el.

```{admonition} Effet de volume partiel
:class: tip
:name: volume-partiel-tip
Il est possible que la segmentation automatique nous retourne pour certains tissus non-d√©sir√©s des valeurs similaires √† celle de la mati√®re grise sur l'image r√©sultant de cette √©tape.
En effet, il est possible que des voxels se trouvant directement sur la jonction entre une zone blanche et une zone noire (par exemple, sur une paroi de mati√®re blanche qui borderait un ventricule) aient comme valeur r√©sultante une valeur s'apparentant plut√¥t au gris associ√© √† la mati√®re grise (valeur moyenne entre blanc et noir).
On appelle ce genre d'effet de m√©lange de noir et de blanc un volume partiel (une partie du volume du voxel est blanche alors que l'autre partie est noire).
```

### Lissage
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
# Importe les librairies n√©cessaires
import matplotlib.pyplot as plt
import numpy as np
from myst_nb import glue
import seaborn as sns

import warnings
warnings.filterwarnings("ignore")

# T√©l√©charge un scan anatomique (template MNI152)
from nilearn import datasets
mni = datasets.fetch_icbm152_2009()

# Initialise la figure
fig = plt.figure(figsize=(15, 15))

from nilearn.plotting import plot_anat
from nilearn.image import math_img
from nilearn.input_data import NiftiMasker
from nilearn.image import smooth_img

list_fwhm = (0, 5, 8, 10)
n_fwhm = len(list_fwhm)
coords = [-5, 5, -25]

for num, fwhm in enumerate(list_fwhm):
    ax_plot = plt.subplot2grid((n_fwhm, 1), (num, 0), colspan=1)
    vol = smooth_img(mni.gm, fwhm)
    plot_anat(vol,
              cut_coords=coords,
              axes=ax_plot,
              black_bg=True,
              title=f'FWHM={fwhm}',
              vmax=1)

from myst_nb import glue
glue("smoothing-fig", fig, display=False)
```
```{glue:figure} smoothing-fig
:figwidth: 600px
:name: smoothing-fig
Illustration de l'impact du lissage sur une carte de densit√© de mati√®re grise en VBM.
√Ä mesure que le param√®tre `FWHM` augmente, la mesure de la densit√© repr√©sente une r√©gion entourant le voxel de plus en plus grande.
Cette figure est g√©n√©r√©e par du code python √† l'aide de la librairie [nilearn](https://nilearn.github.io/) √† partir d'un jeu de donn√©es public appel√© template MNI152 2009 {cite:p}`Fonov2011-xr` (cliquer sur + pour voir le code).
```

L'√©tape suivante correspond au *lissage spatial*.
Celui-ci consiste √† ajouter un filtre sur l'image qui va la rendre plus floue.
En pratique, le lissage remplace la valeur associ√©e √† chaque voxel par une moyenne pond√©r√©e de ses voisins.
Comme c'est une moyenne pond√©r√©e, la valeur originale du voxel est celle qui aura la plus grande pond√©ration, mais les valeurs des voxels situ√©s directement autour vont aussi l'affecter grandement.
La valeur des poids suit le profil d'une distribution Gaussienne 3D (plus un voxel voisin est loin du voxel d'int√©r√™t, moins il en affectera la valeur).
Il est n√©cessaire de proc√©der √† cette √©tape afin d'obtenir des valeurs de densit√© de mati√®re grise pour des zones qui d√©passe le voxel unique, mais qui repr√©sentent plut√¥t le volume d'une petite r√©gion, centr√©e sur le voxel.
La taille de la r√©gion est contr√¥l√©e par un param√®tre de _largeur √† mi-hauteur_, ou `FWHM` (_full width at half maximum_), qui se mesure en millim√®tres.
Plus la valeur de FWHM est grande, plus grand sera le rayon du voisinage contenant les voxels qui auront un impact sur la valeur liss√©e du voxel (voir la {numref}`smoothing-fig`).

### Analyses statistiques
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
import numpy as np
import matplotlib.pyplot as plt
from nilearn import datasets
from nilearn.input_data import NiftiMasker
from nilearn.image import get_data

n_subjects = 100  # more subjects requires more memory

# Charge les donn√©es
oasis_dataset = datasets.fetch_oasis_vbm(n_subjects=n_subjects)
gray_matter_map_filenames = oasis_dataset.gray_matter_maps
age = oasis_dataset.ext_vars['age'].astype(float)

# Pr√©traitement (mask)
nifti_masker = NiftiMasker(
    standardize=False,
    smoothing_fwhm=2,
    memory='nilearn_cache')  # cache options

# Normalise les donn√©es
gm_maps_masked = nifti_masker.fit_transform(gray_matter_map_filenames)

from sklearn.feature_selection import VarianceThreshold
variance_threshold = VarianceThreshold(threshold=.01)

gm_maps_thresholded = variance_threshold.fit_transform(gm_maps_masked)
gm_maps_masked = variance_threshold.inverse_transform(gm_maps_thresholded)
data = variance_threshold.fit_transform(gm_maps_masked)

# Mod√®le de r√©gression massivement univari√©
from nilearn.mass_univariate import permuted_ols
neg_log_pvals, t_scores_original_data, _ = permuted_ols(
    age, data,  # + intercept as a covariate by default
    n_perm=2000,  # 1,000 in the interest of time; 10000 would be better
    verbose=1, # display progress bar
    n_jobs=1)  # can be changed to use more CPUs
signed_neg_log_pvals = neg_log_pvals * np.sign(t_scores_original_data)
signed_neg_log_pvals_unmasked = nifti_masker.inverse_transform(
    variance_threshold.inverse_transform(signed_neg_log_pvals))

# Visualise les r√©sultats
threshold = -np.log10(0.1)  # 10% corrected

fig = plt.figure(figsize=(10, 3), facecolor='k')
bg_filename = gray_matter_map_filenames[0]
cut_coords = [0, 0, 0]
display = plot_stat_map(signed_neg_log_pvals_unmasked, bg_img=bg_filename,
                        threshold=threshold, cmap=plt.cm.RdBu_r,
                        cut_coords=cut_coords,
                        figure=fig)
title = ('Negative $\\log_{10}$ p-values'
         '\n(Non-parametric + max-type correction)')
display.title(title, y=1.2)
plt.show()

from myst_nb import glue
glue("vbm-fig", fig, display=False)
```
```{glue:figure} vbm-fig
:figwidth: 600px
:name: vbm-fig
R√©gression lin√©aire en VBM.
On teste ici l'effet de l'√¢ge sur un groupe (N=50) de participants de la base de donn√©es OASIS.
La significativit√© $-\log_{10}(p)$ de l'effet de l'√¢ge est superpos√©e √† une image de densit√© de mati√®re grise.
Cette figure est adapt√©e d'un tutoriel [Nilearn](https://nilearn.github.io/auto_examples/02_decoding/plot_oasis_vbm.html#sphx-glr-auto-examples-02-decoding-plot-oasis-vbm-py).
```

Afin de pouvoir comparer les valeurs de densit√© de mati√®re grise entre les sujets, on utilise la m√™me proc√©dure de {ref}`recalage <registration-tip>` non-lin√©aire que pour la volum√©trie automatique.
Contrairement √† la volum√©trie manuelle, o√π chaque volume √† l'√©tude est d√©limit√© de fa√ßon √† repr√©senter la m√™me structure d'int√©r√™t, le recalage utilis√© en VBM n'est pas li√© √† une structure particuli√®re.
Une fois les cartes de densit√© recal√©es dans l'espace st√©r√©otaxique de r√©f√©rence, on peut proc√©der √† des tests statistiques √† chaque voxel.
Dans l'exemple ci-dessus, on teste l'effet de l'√¢ge sur la mati√®re grise.
C'est g√©n√©ralement ce genre d'image qui sera par la suite ins√©r√© √† l'int√©rieur des publications scientifiques.

### Contr√¥le de qualit√©
```{figure} ./morphometrie/segmentation-error-volume-fig.png
---
width: 600px
name: segmentation-error-volume-fig
---
Image de gauche: IRM individuelle pond√©r√©e en T1.
Image de droite: classification mati√®re grise et mati√®re blanche g√©n√©r√©e par le logiciel [ANTS](http://stnava.github.io/ANTs/).
Notez comment la mati√®re blanche proche du gyrus est classifi√© de mani√®re erronn√©e comme mati√®re grise.
Image sous licence CC Attribution, tir√©e de Klein et al., 2017 {cite:p}`Klein2017-zh`.
```

Comme pour toute op√©ration automatis√©e, il existe toujours une possibilit√© d'erreur en VBM.
Il est donc n√©cessaire de pr√©voir une √©tape de contr√¥le de qualit√© afin de s'assurer qu'il n'y a pas eu d'aberrations qui se sont introduites dans les √©tapes de traitement.
On a d√©j√† discut√© des artefacts dans les donn√©es ainsi que des probl√®mes de recalage.
La VBM est aussi tr√®s sensible aux erreurs dans l'√©tape de la segmentation.
Il est donc possible de perdre certaines structures pour lesquelles le contraste entre la mati√®re blanche et la mati√®re grise n'est pas assez important pour que l'algorithme r√©ussisse √† les classifier efficacement.
Pour ce genre de structure, il est important d'ajouter des *a priori* (des r√®gles ou des conditions suppl√©mentaires) afin de ne pas les perdre.
Il est aussi envisageable de corriger cette partie de la segmentation de fa√ßon manuelle ou d'exclure les donn√©es de certains participants.

## Analyses de surface

### Extraction de surface
```{figure} ./morphometrie/surface-fig.png
---
width: 600px
name: surface-fig
---
Illustration de la position de la surface piale et de la surface int√©rieure.
En haut: coupe d'IRM pond√©r√©e en T1 avec les surfaces estim√©es de mani√®re automatique.
En bas: illustration sch√©matique des surfaces.
Figure adapt√©e par P. Bellec √† partir de figures de l'article de Klein et al., 2017 {cite:p}`Klein2017-zh` sous licence CC-BY.
```

Les analyses de surface corticale diff√®rent des pr√©c√©dentes techniques de morphom√©trie en ce qu'elles exploitent le ruban que la mati√®re grise forme en s'√©tendant √† la surface de la mati√®re blanche.
En plus des √©tapes de segmentation et de recalage que l'on a vu pr√©c√©demment, on va utiliser ici un algorithme qui va d√©tecter la *surface piale*, √† la fronti√®re entre la mati√®re grise et le liquide c√©phalo-rachidien, et la *surface int√©rieure* (aussi appel√©e *surface blanche*), √† la fronti√®re entre la mati√®re blanche et la mati√®re grise.
Il faudra √©galement, comme pour la VBM, extraire un masque du cerveau en √©liminant les structures n'appartenant pas au cortex (bo√Æte cr√¢nienne, tissus adipeux, m√©ninges, liquide c√©phalo-rachidien, etc.).
Ce genre d'analyse permet de produire des surfaces donnant lieu √† de [magnifiques visualisations interactives](https://gallantlab.org/huth2016/).

```{admonition} Croissance de ballon
:class: tip
Pour estimer la position des surfaces piale et int√©rieure, on place un ballon virtuel au centre de chacun des h√©misph√®res du cerveau.
On mod√©lise ensuite des contraintes physiques √† la fronti√®re entre la mati√®re blanche et la mati√®re grise (surface interne).
On proc√®de ensuite √† "gonfler" ce ballon jusqu'√† ce qu'il √©pouse le mieux possible la fronti√®re de la surface interne (jusqu'√† ce que le ballon soit gonfl√© et occupe tout l'espace dans la cavit√© et qu'il √©pouse l'ensemble des courbes de la paroi).
Il est aussi possible de faire la proc√©dure inverse.
On pourrait en effet g√©n√©rer un ballon virtuel autour de chacun des h√©misph√®res et les "d√©gonfler" jusqu'√† ce qu'ils √©pousent les contours des fronti√®res d√©limit√©es par les contraintes physiques.
Lorsque l'une des fronti√®res (surface interne ou surface piale) est d√©limit√©e, il est possible de continuer la proc√©dure de gonflement/d√©gonflement afin d'obtenir la seconde surface.
```

```{admonition} Attention
:class: caution attention
:name: controle-qualite-attention
Les techniques d'extraction de surface telles que celles propos√©es par le logiciel FreeSurfer sont co√ªteuses en terme de ressources de calcul.
G√©n√©rer une surface √† partir d'une IRM structurelle peut prendre jusqu'√† 10 heures sur un ordinateur standard.
```

### √âpaisseur, surface et volume
```{figure} ./morphometrie/thickness-fig.png
---
width: 600px
name: thickness-fig
---
Illustration des mesures de surface, d'√©paisseur et de volume du cortex.
Figure adapt√©e par P. Bellec √† partir de figures de l'article de Winkler et al., 2018 {cite:p}`Winkler2018-wq` sous licence CC-BY.
```

La reconstruction de la g√©om√©trie de la surface va permettre de d√©composer le volume de la mati√®re grise en une √©paisseur locale, et une surface locale.
Ces deux propri√©t√©s peuvent maintenant √™tre √©tudi√©es s√©par√©ment, contrairement √† ce qu'il est possible de faire avec une analyse VBM, et il a √©t√© d√©montr√© qu'elles sont li√©es de mani√®re ind√©pendante √† diff√©rentes conditions neurologiques et psychiatriques.
Pour ce faire, au lieu d'analyser le contenu d'unit√©s de volume (voxels), comme c'√©tait le cas pour la VBM, on utilisera ici l'analyse du contenu d'unit√©s de surface: les **vertex**.

```{admonition} Attention
:class: caution attention
:name: surface-warning
Qui dit surface corticale, sous-entend aussi que les structures sous-corticales sont laiss√©es de c√¥t√©.
Pour les structures enfouies dans la bo√Æte cr√¢nienne, telles que les thalami et les ganglions de la base, il faut combiner l'analyse de surface avec une volum√©trie automatique (pour les structures sous-corticales).
```

### Analyses statistiques
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
from nilearn import datasets
fsaverage = datasets.fetch_surf_fsaverage()

from nilearn.plotting import plot_surf_stat_map
from nilearn.surface import vol_to_surf
fig = plt.figure(figsize=(10, 8))

texture = vol_to_surf(signed_neg_log_pvals_unmasked, fsaverage.pial_right)

plot_surf_stat_map(fsaverage.white_right, texture, hemi='right', view='lateral',
                            title='Surface blanche h√©misph√®re droit', colorbar=True,
                            threshold=0.5, bg_map=fsaverage.sulc_right,
                            figure=fig)

from myst_nb import glue
glue("surf-stat-fig", fig, display=False)
```
```{glue:figure} surf-stat-fig
:figwidth: 700px
:name: surf-stat-fig
Projection de la carte statistique pr√©sent√©e √† la {numref}`vbm-fig` sur l'atlas de surface corticale `fsaverage`. Cette figure est adapt√©e d'un tutoriel [Nilearn](https://nilearn.github.io/modules/generated/nilearn.plotting.plot_surf_stat_map.html).
```

Les analyses statistiques fonctionnent exactement de la m√™me fa√ßon pour les analyses de surface que pour la VBM.
Mais √† la place de faire un test statistique au niveau de chacun des voxels (comme en VBM), on fait maintenant un test pour chacun des vertex (surface).

### Contr√¥le de qualit√©
```{figure} ./morphometrie/segmentation-error-surface-fig.png
---
width: 600px
name: segmentation-error-surface-fig
---
Image de gauche: IRM individuelle pond√©r√©e en T1.
Image de droite: Extraction de surface automatis√©e.
Notez que la surface piale ne suit pas correctement l'interface entre la mati√®re grise et le liquide c√©phalo-rachidien √† l'endroit indiqu√©.
Image sous licence CC Attribution, tir√©e de Klein et al., 2017 {cite:p}`Klein2017-zh`.
```
La technique d'extraction de surface n'est pas robuste aux effets des volumes partiels.
On pourrait en effet avoir une surface qui ne se rend pas jusqu'au fond d'un sulcus, ou lorsque les gyri sont tr√®s rapproch√©s, qui n'entre m√™me pas √† l'int√©rieur du sulcus.
Le r√©sultat de ces deux types d'erreur, qui sont possibles tant au niveau de la surface piale que de la surface interne, sera une forte surestimation localis√©e de l'√©paisseur corticale.
C'est pourquoi il est souhaitable de proc√©der √† des contr√¥les de qualit√© fr√©quemment sur l'ensemble des images et de corriger les erreurs de segmentation √† la main, ou bien d'exclure les donn√©es de certains participants.

## Conclusion
Ce chapitre vous a introduit aux diff√©rentes familles de techniques de morphologie computationnelle qu'il est possible d'utiliser avec des donn√©es acquises en imagerie par r√©sonance magn√©tique anatomique.
On y a discut√© de plusieurs techniques cl√©s d'analyse d'image et l'on a commenc√© √† introduire certains mod√®les statistiques.

## Exercices

```{admonition} Exercice 1
:class: note

Pour chacun des √©nonc√©s suivants, sp√©cifiez si l'affirmation est vraie ou fausse.
 1. Les mouvements d‚Äôun participant de recherche peuvent cr√©er du bruit dans une carte VBM.
 2. La pr√©sence de m√©tal peut cr√©er du bruit et des d√©formations dans une carte VBM.
 3. Un trou dans une carte c√©r√©brale VBM signifie n√©cessairement qu'il y a un trou dans le cerveau du participant.
```

```{admonition} Exercice 2
:class: note

Pour chacun des √©nonc√©s suivants, sp√©cifiez si l'affirmation est vraie ou fausse.
 1. Les donn√©es IRM doivent √™tre recal√©es dans un espace st√©r√©otaxique pour √©tudier la morphologie du cerveau √† l‚Äô√©chelle d‚Äôune population en VBM.
 2. Les donn√©es IRM doivent √™tre recal√©es dans un espace st√©r√©otaxique pour effectuer une segmentation manuelle de l‚Äôhippocampe.
 3. La VBM repose sur la segmentation automatique de la mati√®re grise dans une IRM.
```

```{admonition} Exercice 3
:class: note

Choisissez la bonne r√©ponse. Des donn√©es d‚ÄôIRM pond√©r√©es en T1 pour un participant sont...
 1. Une image 3D d‚Äôun cerveau.
 2. Des dizaines d‚Äôimages 2D sagittales d‚Äôun cerveau.
 3. Des dizaines d‚Äôimages 2D axiales, coronales et sagittales d‚Äôun cerveau.
 4. Toutes ces r√©ponses.
```

```{admonition} Exercice 4
:class: note

En v√©rifiant ses donn√©es structurelles, une chercheuse r√©alise qu‚Äôun de ses participants de recherche a un volume c√©r√©bral de deux fois sup√©rieur √† la normale!
Pourtant, le cr√¢ne de ce participant semblait normal.
Proposez une explication.
```

```{admonition} Exercice 5
:class: note

On souhaite faire une comparaison entre la quantit√© de mati√®re grise pr√©sente au niveau du cortex moteur primaire et celle contenue dans le cortex sensoriel primaire, en moyenne, sur une population. Ces deux cortex sont situ√©s tr√®s pr√®s l‚Äôun de l‚Äôautre, de part et d‚Äôautre du sillon central. On consid√®re pour cela deux m√©thodes alternatives: une analyse VBM ou bien une analyse de l‚Äô√©paisseur corticale (analyse de surface).
Quelle technique choisiriez-vous et pourquoi?
```

```{admonition} Exercice 6
:class: note
On souhaite comparer le volume moyen de l‚Äôhippocampe droit entre des participants pr√©sentant une d√©mence de type Alzheimer et des participants en sant√©. On fait l‚Äôhypoth√®se que c‚Äôest la partie ant√©rieure de l‚Äôhippocampe qui pr√©sente une diff√©rence.
On consid√®re pour cela deux m√©thodes alternatives: la volum√©trie manuelle et l'analyse VBM.
Pour chacune de ces techniques, citez une force et une faiblesse en lien avec les objectifs de l'√©tude.
```

```{admonition} Exercice 7
:class: note

Pour r√©pondre aux questions de cet exercice, lisez d'abord l'article *Development of cortical thickness and surface area in autism spectrum disorder* de Mensen et collaborateurs (publi√© en 2017 dans la revue *Neuroimage: Clinical*, volume 13, pages 215 √† 222).
Celui-ci est disponible en libre acc√®s √† cette [adresse](https://www.sciencedirect.com/science/article/pii/S2213158216302406).
Les questions suivantes requi√®rent des r√©ponses √† d√©veloppement court.
 - Quelle technique de neuroimagerie est utilis√©e? S'agit-il d'une technique structurelle ou fonctionnelle?
 - Est ce que le traitement des images inclut une(des) √©tape(s) de recalage? Si oui, de quel(s) type(s)?
 - Les chercheurs ont-ils mis en place une proc√©dure de contr√¥le qualit√©? Si oui, r√©sumez cette proc√©dure.
 - Les r√©gions d'int√©r√™t (ROI) sont-elles d√©finies? Si oui, de quelle fa√ßon? Avec quel atlas? Combien y en a-t-il?
 - Quelles mesures morphologiques sont utilis√©es pour chaque r√©gion?
```
